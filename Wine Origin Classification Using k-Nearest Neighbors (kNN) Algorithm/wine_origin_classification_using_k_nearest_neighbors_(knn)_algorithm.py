# -*- coding: utf-8 -*-
"""Wine Origin Classification Using k-Nearest Neighbors (kNN) Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h2A2f8UPpwyj7vWJDnYlQQkeCnq7x16Q

#**Wine Origin Classification Using k-Nearest Neighbors (kNN) Algorithm**

Wine has been a beverage of choice for centuries, enjoyed for its diverse flavors and characteristics. The origin of a wine can significantly impact its taste and quality. In this project, we will dive together into the fascinating world of wine classification by leveraging the power of machine learning, specifically the **k-Nearest Neighbors (kNN) algorithm**.

The goal of this project is to accurately classify the origin of wines based on their chemical composition. We will utilize the Wine Data Set from the UCI Machine Learning Repository, these data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different varieties. The analysis determined the quantities of 13 constituents found in each of the three types of wines.

With the aid of the kNN algorithm, we aim to create a model that can distinguish between these wine varieties with precision. To achieve this, we will explore **three different values of k**, a crucial hyperparameter in the kNN algorithm, and make informed decisions regarding data preprocessing and model evaluation. We will use **all 13 available features** in the dataset to train and test our classifier.

The features are:
* Alcohol
* Malic acid
* Ash
* Alcalinity of ash  
* Magnesium
* Total phenols
* Flavanoids
* Nonflavanoid phenols
* Proanthocyanins
* Color intensity
* Hue
* OD280/OD315 of diluted wines
* Proline

The project will provide insights into the performance of the kNN algorithm in wine classification, showcasing metrics such as accuracy, precision, recall, and F1-score for individual classes and overall accuracy. Additionally, we will present the confusion matrix to gain a deeper understanding of the model's classification performance.

To summarize:

1. Import libraries.
2. Import dataset
3. Explore the dataset.
4. Split the dataset into training and test sets.
5. Scale the features.
6. Use GridSearchCV for hyperparameter tuning.
7. Select two different values of k base on GridSearchCV.
8. Use the k-Nearest Neighbors (kNN) algorithm to classify wine origin based on chemical analysis data.
9. Display the confusion matrix.
10. Calculate and display accuracy, precision, recall, and f1-score per class and overall.
11. Optimization of k-NN algorithm with a pipeline

Join me on this journey as we explore the potential of machine learning in the world of oenology and discover how kNN can help us identify the origin of wines with finesse and accuracy.

You can find more details for the dataset [here](http://archive.ics.uci.edu/ml/datasets/Wine).

Download the dataset from [here](https://drive.google.com/file/d/1OKzRlTnmJavmXBJjRhUZO_VA-u_dqylN/view?usp=share_link)

Import libraries
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

"""I'm using the Google Colab Environment"""

# Access files and data stored in Google Drive within a Colab environment
from google.colab import drive
drive.mount('/content/drive')

"""Import data"""

# Access a file in Google Drive
data_path = '/content/drive/MyDrive/Dataset/wine-data.csv'

# Read a CSV file into a DataFrame
df = pd.read_csv(data_path)

# Display the first 5 rows of the DataFrame 'df'
df.head()

# Get the dimensions (number of rows and columns) of the DataFrame 'df'
df.shape

# Display information about the DataFrame, including data types and non-null counts
df.info()

# Check and display the count of missing values (NaN) in each column of the DataFrame
df.isnull().sum()

# Generate summary statistics for numerical columns in the DataFrame
df.describe().transpose()

# Remove leading and trailing whitespaces from column names
df.columns = df.columns.str.strip()

# Get the column names of the DataFrame 'df'
df.columns

# Get unique values in the 'Class' column
df['Class'].unique()

"""Percentage Distribution"""

# Calculate and round the percentage distribution of each unique class in the 'Class' column
class_distribution_percentage = round(df['Class'].value_counts(normalize=True, sort=False) * 100)

# Print the percentage distribution
print(class_distribution_percentage)

"""Plot a histogram for each column"""

# Create a color palette with distinct colors
palette = sns.color_palette("Set3", n_colors=len(df.columns))

# Create a 4x4 grid of subplots in a figure with a specified size
fig, axs = plt.subplots(ncols=4, nrows=4,  figsize=(20, 10))

# Flatten the 2D array of subplots into a 1D array
axs = axs.flatten()

# Iterate through each column of the DataFrame and create a histogram for each with a different color
for i, (column_name, column_data) in enumerate(df.items()):
    sns.histplot(column_data, ax=axs[i], color=palette[i], kde=True).lines[0].set_color('red')  # Use a distinct color for each histogram

# Remove any empty subplots because of fewer features
for j in range(len(df.columns), 16):
    fig.delaxes(axs[j])

# Adjust the layout of subplots for better spacing
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

# Display the created plots
plt.show()

"""Plot correlation heatmap"""

# Create a matplotlib figure with a specified figsize
plt.figure(figsize=(20, 10))

# Set the title for the figure
plt.title('Correlation Heatmap',fontsize = 20)

# We will use the variable called mask to remove the values across the heatmap diagonally as it will be the same
mask = np.triu(np.ones_like(df.corr()))

# Create a correlation heatmap
sns.heatmap(df.corr(), annot=True, cmap = 'icefire', mask = mask)

# Finally, display the figure
plt.show()

"""Separating features from the target variable"""

# Extract the feature variables (X) from the DataFrame 'df' by dropping the 'Class' column
X = df.drop(['Class'], axis=1).values

# Extract the target variable (y) from the 'Class' column of the DataFrame 'df'
y = df['Class'].values

"""Split data into train and test subsets."""

# Splitting the dataset into training and testing sets with a test size of 20%.
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)

"""Standardize features by removing the mean and scaling to unit variance"""

# Create a StandardScaler object to scale the features.
scaler = StandardScaler()

# Fit the scaler to the training data and transform it to standardize the training features.
X_train_sc = scaler.fit_transform(X_train)

# Transform the testing features using the same scaler to ensure consistent scaling.
X_test_sc = scaler.transform(X_test)

"""Hyperparameter Tuning for K-Nearest Neighbors Classifier"""

# Create an empty list to store the best hyperparameter values
best_parameters = []

# Initialize a counter variable
kk = 0

# Iterate over a set of values for 'i', which represent different values for 'cv' in GridSearchCV
for i in np.array([5,10]):
    # Define the hyperparameter grid for KNeighborsClassifier
    grid = {'n_neighbors': list(range(1, 16))}

    # Create a GridSearchCV object for hyperparameter tuning
    est = GridSearchCV(KNeighborsClassifier(), grid, scoring='balanced_accuracy', n_jobs=-1, cv=i, verbose=0)

    # Fit the GridSearchCV object to the scaled training data (X_train_sc) and corresponding labels (y_train)
    est.fit(X_train_sc, y_train)

    # Get the best value of 'n_neighbors' hyperparameter
    best_parameters.append(est.best_params_['n_neighbors'])

    # Print the best value of 'n_neighbors' hyperparameter
    print(f'\033[4mk = {best_parameters[kk]}\033[0m')  # Print the best 'n_neighbors' value with formatting

    # Increment the counter
    kk += 1

    # Print the accuracy achieved by the best model found by GridSearchCV
    print(f'Accuracy = {round(est.best_score_, 4)}\n')

"""Evaluation of K-Nearest Neighbors Models with Best Hyperparameters"""

# Iterate through a list of best_parameters
for i in range(len(best_parameters)):

  # Create a K-Nearest Neighbors classifier with the current value of best_parameters[i]
  model = KNeighborsClassifier(n_neighbors = best_parameters[i])

  # Fit the model to the training data
  model.fit(X_train_sc, y_train)

  # Make predictions on the test data
  predictions = model.predict(X_test_sc)

  # Calculate the confusion matrix
  cm = confusion_matrix(y_test, predictions)

  # Print the value of k (number of neighbors) for this iteration
  print(f'\033[4mk = {best_parameters[i]}\033[0m', '\n')

  # Print the confusion matrix
  print('Confusion Matrix\n', cm, '\n')

  # Print the classification report, which includes various metrics for evaluating the model's performance
  print('Classification Report:\n\n', classification_report(y_test, predictions),'\n\n')

"""###Optimization of k-NN algorithm with a pipeline

Create pipeline
"""

# Create a pipeline with two steps: data scaling and classification
pipe = Pipeline([
    ('scaler', StandardScaler()),        # Step 1: Data scaling using StandardScaler
    ('classifier', KNeighborsClassifier())  # Step 2: Classification using KNeighborsClassifier
])

"""Parameters for GridSearchCV"""

# Define a parameter grid for hyperparameter tuning
parameters = {
    'scaler': [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],  # Try different scalers
    'classifier': [KNeighborsClassifier()],  # Use the KNeighborsClassifier for this grid search
    'classifier__n_neighbors': list(range(1, 16))  # Hyperparameter tuning for the number of neighbors
}

"""Hyperparameter Tuning"""

# Create a GridSearchCV object for hyperparameter tuning
est = GridSearchCV(pipe, parameters, scoring='balanced_accuracy', n_jobs=-1, cv=5, verbose=0)

# Fit the GridSearchCV object to the training data (X_train) and corresponding labels (y_train)
est.fit(X_train, y_train)

# Get the best value of 'n_neighbors' hyperparameter
best_parameter = est.best_params_['classifier__n_neighbors']

# Print the best value of 'n_neighbors' hyperparameter
print(f'\033[4mk = {best_parameter}\033[0m')  # Print the best 'n_neighbors' value with formatting

# Print the accuracy achieved by the best model found by GridSearchCV
print(f'Accuracy = {round(est.best_score_, 4)}\n')

"""The best pipeline"""

# Set 'pipe' to the best estimator found by grid search
pipe = est.best_estimator_

"""Fit the pipeline"""

# Fit the best estimator to the training data
pipe.fit(X_train, y_train)

# Scale the test data using  MinMaxScaler
X_test_sc = pipe.named_steps['scaler'].transform(X_test)

"""Pipeline predictions"""

# Make predictions on the scaled test data
predictions = pipe.named_steps['classifier'].predict(X_test_sc)

"""Confusion matrix"""

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

"""Print pipelines confusion matrix and classification report"""

# Print the confusion matrix
print('Confusion Matrix\n', cm, '\n')

# Print the classification report, which includes various metrics for evaluating the model's performance
print('Classification Report:\n\n', classification_report(y_test, predictions),'\n\n')

"""#Conclusion
In conclusion, by employing pipeline and an organized hyperparameter search strategy, it successfully improves the k-NN classifier's performance on the given dataset. The pipeline ensures data consistency and mitigates potential issues, while the systematic hyperparameter tuning optimizes the model's configuration. The comprehensive evaluation provides insights into the model's strengths and weaknesses. Overall, this approach results in a more accurate, robust, and well-tuned k-NN classifier, ready to make informed predictions on new data.

#Thank You!!!
"""